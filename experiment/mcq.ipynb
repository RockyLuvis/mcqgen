{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (3.10.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (0.2.13)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (0.2.31)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ravib\\mcqgen\\mcqgen_env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "dotenvobj = load_dotenv()\n",
    "#os.getenv(OPENAI_API_KEY)\n",
    "KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print (KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key = KEY, model_name = \"gpt-3.5-turbo\", temperature = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCQ Generator : MCQ model is where GPT based on the given paragraph/pdf it will generate MCQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given a text, please create a quiz of {number} multiple choice questions\n",
    "for {subject} students in {tone} tone.\n",
    "Use json a response format.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate (\n",
    "    input_variables = [\"text\", \"number\", \"subject\", \"tone\"],\n",
    "    template = TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Who won the Olympics gold medal in 400m running men?\n",
      "You are an expert MCQ maker. Given a text, please create a quiz of 4 multiple choice questions\n",
      "for Olympics students in simple tone.\n",
      "Use json a response format.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mcq = LLMChain ( llm=llm, prompt=prompt, output_key=\"quiz\", verbose=True)\n",
    "result = mcq.run({\n",
    "    \"text\": \"Who won the Olympics gold medal in 400m running men?\",\n",
    "    \"subject\": \"Olympics\",\n",
    "    \"number\": \"4\",\n",
    "    \"tone\": \"simple\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"question\": \"Who won the Olympics gold medal in 400m running men?\",\n",
      "  \"options\": {\n",
      "    \"A\": \"Usain Bolt\",\n",
      "    \"B\": \"Wayde van Niekerk\",\n",
      "    \"C\": \"Michael Johnson\",\n",
      "    \"D\": \"LaShawn Merritt\"\n",
      "  },\n",
      "  \"correct_answer\": \"B\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\n",
      "  \"question1\": {\n",
      "    \"question\": \"Who won the gold medal in men's 400m running at the Olympics?\",\n",
      "    \"options\": [\n",
      "      \"Usain Bolt\",\n",
      "      \"Wayde van Niekerk\",\n",
      "      \"Michael Johnson\",\n",
      "      \"Carl Lewis\"\n",
      "    ],\n",
      "    \"answer\": \"Wayde van Niekerk\"\n",
      "  },\n",
      "  \"question2\": {\n",
      "    \"question\": \"In which year did the athlete win the gold medal in the men's 400m running at the Olympics?\",\n",
      "    \"options\": [\n",
      "      \"2000\",\n",
      "      \"2008\",\n",
      "      \"2012\",\n",
      "      \"2016\"\n",
      "    ],\n",
      "    \"answer\": \"2016\"\n",
      "  },\n",
      "  \"question3\": {\n",
      "    \"question\": \"Which country does the gold medalist Wayde van Niekerk represent?\",\n",
      "    \"options\": [\n",
      "      \"Jamaica\",\n",
      "      \"United States\",\n",
      "      \"South Africa\",\n",
      "      \"Canada\"\n",
      "    ],\n",
      "    \"answer\": \"South Africa\"\n",
      "  },\n",
      "  \"question4\": {\n",
      "    \"question\": \"What is the distance of the race for which Wayde van Niekerk won the gold medal at the Olympics?\",\n",
      "    \"options\": [\n",
      "      \"100m\",\n",
      "      \"200m\",\n",
      "      \"400m\",\n",
      "      \"800m\"\n",
      "    ],\n",
      "    \"answer\": \"400m\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(type(result))\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(result, dict):\n",
    "    print(result[\"quiz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "    Given multiple choice quiz for {subject} students.\n",
    "    Update the quiz questions as per the analytical abilities of the student\n",
    "    change the tone that perfectly fits the students ability\n",
    "    Quiz_MCQs = {quiz}\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables = [\"subject\", \"quiz\"],\n",
    "    template = TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['quiz', 'subject'], template='\\n    Given multiple choice quiz for {subject} students.\\n    Update the quiz questions as per the analytical abilities of the student\\n    change the tone that perfectly fits the students ability\\n    Quiz_MCQs = {quiz}\\n\\n')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Quiz evaluation chain,  llm=llm, prompt=prompt, output_key=\"quiz\", verbose=True\n",
    "review_chain = LLMChain (llm = llm, prompt = quiz_evaluation_prompt, output_key = \"review\", verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Given multiple choice quiz for olympics students.\n",
      "    Update the quiz questions as per the analytical abilities of the student\n",
      "    change the tone that perfectly fits the students ability\n",
      "    Quiz_MCQs = {\n",
      "  \"question1\": {\n",
      "    \"question\": \"Who won the gold medal in men's 400m running at the Olympics?\",\n",
      "    \"options\": [\n",
      "      \"Usain Bolt\",\n",
      "      \"Wayde van Niekerk\",\n",
      "      \"Michael Johnson\",\n",
      "      \"Carl Lewis\"\n",
      "    ],\n",
      "    \"answer\": \"Wayde van Niekerk\"\n",
      "  },\n",
      "  \"question2\": {\n",
      "    \"question\": \"In which year did the athlete win the gold medal in the men's 400m running at the Olympics?\",\n",
      "    \"options\": [\n",
      "      \"2000\",\n",
      "      \"2008\",\n",
      "      \"2012\",\n",
      "      \"2016\"\n",
      "    ],\n",
      "    \"answer\": \"2016\"\n",
      "  },\n",
      "  \"question3\": {\n",
      "    \"question\": \"Which country does the gold medalist Wayde van Niekerk represent?\",\n",
      "    \"options\": [\n",
      "      \"Jamaica\",\n",
      "      \"United States\",\n",
      "      \"South Africa\",\n",
      "      \"Canada\"\n",
      "    ],\n",
      "    \"answer\": \"South Africa\"\n",
      "  },\n",
      "  \"question4\": {\n",
      "    \"question\": \"What is the distance of the race for which Wayde van Niekerk won the gold medal at the Olympics?\",\n",
      "    \"options\": [\n",
      "      \"100m\",\n",
      "      \"200m\",\n",
      "      \"400m\",\n",
      "      \"800m\"\n",
      "    ],\n",
      "    \"answer\": \"400m\"\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Quiz_MCQs = {\\n  \"question1\": {\\n    \"question\": \"Who emerged victorious in the men\\'s 400m race at the Olympics, showcasing unparalleled speed and determination?\",\\n    \"options\": [\\n      \"Usain Bolt\",\\n      \"Wayde van Niekerk\",\\n      \"Michael Johnson\",\\n      \"Carl Lewis\"\\n    ],\\n    \"answer\": \"Wayde van Niekerk\"\\n  },\\n  \"question2\": {\\n    \"question\": \"Can you recall the year when the talented athlete clinched the gold medal in the men\\'s 400m event at the Olympics?\",\\n    \"options\": [\\n      \"2000\",\\n      \"2008\",\\n      \"2012\",\\n      \"2016\"\\n    ],\\n    \"answer\": \"2016\"\\n  },\\n  \"question3\": {\\n    \"question\": \"From which nation does the remarkable gold medalist Wayde van Niekerk proudly represent on the global stage?\",\\n    \"options\": [\\n      \"Jamaica\",\\n      \"United States\",\\n      \"South Africa\",\\n      \"Canada\"\\n    ],\\n    \"answer\": \"South Africa\"\\n  },\\n  \"question4\": {\\n    \"question\": \"Do you know the exact distance of the fierce race that propelled Wayde van Niekerk to victory at the Olympics?\",\\n    \"options\": [\\n      \"100m\",\\n      \"200m\",\\n      \"400m\",\\n      \"800m\"\\n    ],\\n    \"answer\": \"400m\"\\n  }\\n}'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_chain.run({\n",
    "    \"subject\": \"olympics\",\n",
    "    \"quiz\": result\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a sequential chain\n",
    "\n",
    "mcq_evaluate_chain = SequentialChain (\n",
    "    chains = [mcq, review_chain],\n",
    "    input_variables = [\"text\", \"number\", \"subject\", \"tone\" ],\n",
    "    output_variables = [\"quiz\", \"review\"],\n",
    "    verbose = True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to track token usage tracking, using Get OpenAI callback,, with this we get Input Token Number, Output Token Number\n",
    "Search for Token_usage_tracking on python.langchain.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Who won the Olympics gold medal in 400m running men?\n",
      "You are an expert MCQ maker. Given a text, please create a quiz of 4 multiple choice questions\n",
      "for Olympics students in simple tone.\n",
      "Use json a response format.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    Given multiple choice quiz for Olympics students.\n",
      "    Update the quiz questions as per the analytical abilities of the student\n",
      "    change the tone that perfectly fits the students ability\n",
      "    Quiz_MCQs = {\n",
      "  \"question\": \"Who won the Olympics gold medal in 400m running men?\",\n",
      "  \"options\": [\n",
      "    {\"A\": \"Usain Bolt\"},\n",
      "    {\"B\": \"Wayde van Niekerk\"},\n",
      "    {\"C\": \"Michael Johnson\"},\n",
      "    {\"D\": \"Carl Lewis\"}\n",
      "  ],\n",
      "  \"answer\": \"B\"\n",
      "}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Response: {'text': 'Who won the Olympics gold medal in 400m running men?', 'subject': 'Olympics', 'number': '4', 'tone': 'simple', 'quiz': '{\\n  \"question\": \"Who won the Olympics gold medal in 400m running men?\",\\n  \"options\": [\\n    {\"A\": \"Usain Bolt\"},\\n    {\"B\": \"Wayde van Niekerk\"},\\n    {\"C\": \"Michael Johnson\"},\\n    {\"D\": \"Carl Lewis\"}\\n  ],\\n  \"answer\": \"B\"\\n}', 'review': 'Quiz_MCQs = {\\n  \"question\": \"In the 2016 Olympics, who set a new world record in the 400m running men event?\",\\n  \"options\": [\\n    {\"A\": \"Usain Bolt\"},\\n    {\"B\": \"Wayde van Niekerk\"},\\n    {\"C\": \"Michael Johnson\"},\\n    {\"D\": \"Carl Lewis\"}\\n  ],\\n  \"answer\": \"B\"\\n}'}\n",
      "++++++++++++++++++++++++++++++++++++\n",
      "Callback info: Tokens Used: 334\n",
      "\tPrompt Tokens: 178\n",
      "\tCompletion Tokens: 156\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.000579\n"
     ]
    }
   ],
   "source": [
    "# Use callback if needed\n",
    "with get_openai_callback() as cb:\n",
    "    try:\n",
    "        # Apply the chain\n",
    "        response = mcq_evaluate_chain({\n",
    "            \"text\": \"Who won the Olympics gold medal in 400m running men?\",\n",
    "            \"subject\": \"Olympics\",\n",
    "            \"number\": \"4\",\n",
    "            \"tone\": \"simple\"\n",
    "        })\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(\"Error:\", e)\n",
    "\n",
    "print(\"Response:\", response)\n",
    "print(\"++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "# Print callback info if needed\n",
    "print(\"Callback info:\", cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'text': 'Who won the Olympics gold medal in 400m running men?', 'subject': 'Olympics', 'number': '4', 'tone': 'simple', 'quiz': '{\\n  \"question\": \"Who won the Olympics gold medal in 400m running men?\",\\n  \"options\": [\\n    {\"A\": \"Usain Bolt\"},\\n    {\"B\": \"Wayde van Niekerk\"},\\n    {\"C\": \"Michael Johnson\"},\\n    {\"D\": \"Carl Lewis\"}\\n  ],\\n  \"answer\": \"B\"\\n}', 'review': 'Quiz_MCQs = {\\n  \"question\": \"In the 2016 Olympics, who set a new world record in the 400m running men event?\",\\n  \"options\": [\\n    {\"A\": \"Usain Bolt\"},\\n    {\"B\": \"Wayde van Niekerk\"},\\n    {\"C\": \"Michael Johnson\"},\\n    {\"D\": \"Carl Lewis\"}\\n  ],\\n  \"answer\": \"B\"\\n}'}\n",
      "++++++++++++++++++++++++++++++++++++\n",
      "{\n",
      "  \"question\": \"Who won the Olympics gold medal in 400m running men?\",\n",
      "  \"options\": [\n",
      "    {\"A\": \"Usain Bolt\"},\n",
      "    {\"B\": \"Wayde van Niekerk\"},\n",
      "    {\"C\": \"Michael Johnson\"},\n",
      "    {\"D\": \"Carl Lewis\"}\n",
      "  ],\n",
      "  \"answer\": \"B\"\n",
      "}\n",
      "++++++++++++++++++++++++++++++++++++\n",
      "Quiz_MCQs = {\n",
      "  \"question\": \"In the 2016 Olympics, who set a new world record in the 400m running men event?\",\n",
      "  \"options\": [\n",
      "    {\"A\": \"Usain Bolt\"},\n",
      "    {\"B\": \"Wayde van Niekerk\"},\n",
      "    {\"C\": \"Michael Johnson\"},\n",
      "    {\"D\": \"Carl Lewis\"}\n",
      "  ],\n",
      "  \"answer\": \"B\"\n",
      "}\n",
      "Callback info: Tokens Used: 334\n",
      "\tPrompt Tokens: 178\n",
      "\tCompletion Tokens: 156\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.000579\n"
     ]
    }
   ],
   "source": [
    "print(\"Response:\", response)\n",
    "print(\"++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "print(response[\"quiz\"])\n",
    "\n",
    "print(\"++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "print(response[\"review\"])\n",
    "\n",
    "# Print callback info if needed\n",
    "print(\"Callback info:\", cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++++++++++++\n",
      "{\n",
      "  \"question\": \"Who won the Olympics gold medal in 400m running men?\",\n",
      "  \"options\": [\n",
      "    {\"A\": \"Usain Bolt\"},\n",
      "    {\"B\": \"Wayde van Niekerk\"},\n",
      "    {\"C\": \"Michael Johnson\"},\n",
      "    {\"D\": \"Carl Lewis\"}\n",
      "  ],\n",
      "  \"answer\": \"B\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "print(response[\"quiz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
